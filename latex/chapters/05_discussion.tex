\addtocontents{toc}{\protect\newpage}
\section{Discussion}
\label{cha:discussion}
The present chapter provides context to the results presented in Chapter \ref{cha:results} regarding the defined research question and the existing work. Initially, the characteristics and suitability of the dataset used to answer the research question are outlined. 
Given the interdependence of the various approaches to efficiently visualize outbreak dynamics, a comparative interpretation of the results for the individual disciplines is provided. First, the resulting savings in computing effort are compared. The results are then analyzed for the preservation of interpretability for outbreak analysis. This includes evaluating the preservation of infection chains and the representation of the outbreak contexts. Finally, the limitations and applicability of the results are discussed.

\subsection{Characteristics and Suitability of the Dataset}
To ensure the representative value of the dataset, it was first analyzed in terms of seasonal and geographic distribution. Concerning seasonal distribution, when the immense strain on the system during periods of high infection rates is taken into account, the total number of positive cases per month during the pandemic is approximately reflected by the dataset. 
As the laboratories that collected sequence samples were mostly located in metropolises, the dataset does not provide a very detailed view of the origin of the sequences. However, it can be assumed to be sufficient for examining a geographic context, as a dependency between sequencing and population density of federal states could be observed.
The dataset comprises multiple variants of the SARS-CoV-2 virus over a seasonal period, indicating a high level of representation in terms of mutation dynamics. As viruses with a genome length similar to that of SARS-CoV-2 are primarily sequenced using short reads, and 92.5~\% of sequences of the dataset derived from short-read technologies, the dataset exhibits a representative distribution.
Sequence availability increases with both the seasonal period and the geographic area. However, clade diversity only correlates with the seasonal period. Therefore, it can be assumed that the seasonal period has a greater impact on mutation dynamics than the geographic area.
Furthermore, it was observed that the number of mutations per sequence increases with the seasonal period but not with the geographic area. This can be explained by the establishment of specific mutations that are inherited during the replication process. Therefore, longer seasonal periods should result in a greater genetic distance and fewer infections. This was also shown by the higher infection rates exhibited from longer seasonal periods. This finding was not surprising, as shorted seasonal periods decrease opportunities for viral replication, so shorter genetic distances are expected. In terms of geographic area, it was found that the sequences collected from Düsseldorf showed significantly higher infection rates. However, there was no significant increase in infection rates between sequences obtained from \acrshort{nrw} and Germany. Therefore, geographic areas appear to impact infection dynamics in very confined regions, such as municipalities, in particular. This may be explained by greater interaction among hosts in urban environments. Additionally, downsampling could be a factor in the deviation of infection rates, as the aggregates comprised very different numbers of sequences, all of which were reduced to 1,250 sequences for the calculation of infection rates.

\subsection{Computational Effort}
The modification of the original GENTRAIN algorithm laid the foundation for the decrease in runtime, resulting in immense savings. Calculating distance matrices for sequence numbers around 2,500 had become feasible through the modified algorithm. However, there was still a significant increase in runtime when considering more sequences due to quadratic scaling. In addition, calculating individual genetic distances remained complex.

The latter issue was resolved using the genetic distance approximation, which reduced the runtime for 5,000 sequences to under 2 minutes. Although 10,000 sequences can be processed in less than 6 minutes, a higher number of sequences demonstrated the limitations of quadratic scaling, even with an efficient execution time for a single genetic distance calculation. \acrshort{ccs} is based on genetic distances approximation and therefore inherits the calculation time of complete approximate genetic distance matrices. However, the method provides exact genetic distances according to the modified algorithm, which is highly relevant for sensible tasks such as disease outbreak analysis. The execution times for calculating sparse distance matrices and generating \acrshortpl{mst} based on these matrices were included in the runtime comparisons. Compared to the modified algorithm, \acrshort{ccs} yielded savings of up to about 90~\% in runtime for a calculation rate of 0.05 and up to about 75~\% for a calculation rate of 0.2.

As a last measure, a solution to overcome the quadratic scaling of the genetic distance matrix calculation was provided with \acrshort{acs}. Selecting an appropriate hash length enabled this approach to avoid quadratic scaling throughout the entire process, including the generation of \acrshortpl{mst}. This was proven for a hash length of 3,000, which exhibited a subquadratic empirical runtime and a time complexity of $O(n^{1.46})$ when sample sizes ranging from 5,000 to 25,000 were considered. Furthermore, the approach required half the runtime of \acrshort{ccs} when considering 10,000 sequences with method configurations that yielded analogous results. As more sequences are considered, the impact of \acrshort{acs} is predicted to increase even further because calculating approximate genetic distance matrices scales quadratically.

In general, these results revealed a significant reduction in the runtime required to generate visualizations for outbreak analysis. This work does not address acceptance criteria regarding runtime for user-oriented applications that support outbreak analysis. However, the significant reduction in runtime achieved is a promising step that contributes to answering the research question of this work.

\subsection{Preservation of Infection Chains}
The preservation of infection chains was first assessed on the basis of complete distance matrices resulting from the algorithm modification and the approximation of genetic distances. As mentioned in Section \ref{sec:optimization_of_the_gentrain_algorithm}, the main objective of the algorithm modification, was to prevent overestimation of genetic distances to avoid missing infectious distances. On average, the errors of the modified algorithm underestimated the modified algorithm for all aggregates. This also applied to the errors obtained regarding infectious distances. The visualization of errors also supported these assumptions. An overestimation of genetic distance was observed in a negligible number of cases, while the underestimation of genetic distance was slightly more prevalent. This underestimation can be explained by a lower increase in genetic distance caused by indels when using the modified algorithm. Using Nextclade to define the alignment range could result in an assessment of shorter sequences compared to using the proper symbol treatment.
However, most of the genetic distances could be almost perfectly attributed to the identity lines for both observed aggregates. The modified algorithm produced very similar genetic distances, particularly for infectious distances, which are the most relevant when analyzing infection chains with \acrshortpl{mst}.

The $\text{sRMSE}$ score for the approximate genetic distance matrices showed that both filter-based encodings led to an underestimation of the genetic distance. In contrast, the encoding without filtering overestimated these distances. This was to be expected, as the consideration of missing symbols is an essential driver for the decision of distance increase. 
An investigation of the $\text{sRMSE}_{inf}$ results yielded positive values in all cases, suggesting that infections were often overestimated by using the genetic distance approximation. In general, the encoding using only \acrshort{nff} resulted in the most adequate distance matrices in terms of the error metrics. When visualizing these errors, a larger deviation was observed compared to the modified algorithm. Although this was expected, the implications have yet to be discussed. Most of the approximate distances adequately reflected the original values. The deviation results were located mainly below the identity line and therefore underestimated the genetic distances. It was evident that the difference between the actual and approximate values increased with increasing genetic distance. Regarding the purpose of this work, this is good news because lower values are the driving factor when generating \acrshortpl{mst}. The approximate genetic distances showed significant offset at larger genetic distances and even immense overestimation for the aggregate nrw\_2022. Although this is by no means negligible, these deviations were accepted because the procedure was intended to prepare for \acrshort{ccs}. Therefore, significant errors will be corrected when calculating exact distances for the relevant sequence pairs only. This emphasizes the importance of the rank-based correlation of the approximate genetic distance matrices, which was obtained using Kendall's $\tau_b$ correlation. The correlation for the original matrices and the one resulting from the modified algorithm showed a strong ordinal association between the genetic distances of the two matrices. For all aggregates, high correlation values were observed, indicating adequate preservation of genetic distance matrices. It was clear that the approximate genetic distance matrices showed lower correlation scores compared to the modified algorithm. The best correlation results were achieved using only \acrshort{nff} with a correlation of about 0.8 for both aggregates. This was not surprising, as this approach was expected to best reflect the behavior of the original algorithm. However, encodings that used both filters also achieved rather strong correlations ranging from 0.671 to 0.764 while significantly shortening the encoding lengths.

The fact that infection recall ranged between 0.978 and 0.993 using the modified algorithm allows the assumption that most infections were correctly identified. An underestimation was also observed when interpreting infection precision scores, which were lower for sequences from Düsseldorf (0.544) than for sequences from NRW (0.732). Since distances were often underestimated, the modified algorithm produced more false positives. Thus, low precision was a logical consequence, which was acceptable given the risk of underestimation that had been taken. In terms of infection recall, the approximation of genetic distances appeared to be better for aggregates with higher infection rates. This was logical, as the error for low genetic distances exhibited lower values. In comparison, the approximate genetic distance matrices showed much lower scores compared to the matrices resulting from the modified algorithm. However, this finding should not be overrated, as the candidate search was based on the rank order of the approximate genetic distance matrices. In fact, when observing the infection recall for \acrshort{ccs} it became evident that even with very low calculation rates, high scores were achieved. Using depth search a median infection recall of 0.833 was achieved for a calculation rate of 0.05, which accelerated to 0.976 for a calculation rate of 0.2. In comparison, breadth search scored much lower. Throughout the set of results, breadth search also showed a higher standard deviation regarding infection recall, showing that the results were more inconsistent compared to depth search. Therefore, the approximation of genetic distance matrices represented an appropriate procedure when used as a preparatory step in a depth search for relevant candidates. The \acrshort{ccs} method, in turn, ensured the accuracy of genetic distance, resulting in higher infection recall scores in the dimensions of the modified algorithm.

Concerning \acrshort{acs} using AND/OR-\acrshort{lsh}, the infection recall was dependent on the hash length and the number of \acrshort{lsh} iterations used, as better scores were achieved with greater hash lengths and numbers of infections. In general, infection recall exhibited higher scores over a longer seasonal period. This could be related to lower infection rates and a greater distance deviation over longer seasonal periods because infections become easier to distinguish from other genetic distances.
Comparable, though slightly lower, infection recall scores were obtained compared to \acrshort{ccs}. This low difference is promising, as the quadratic scaling was circumvented when an adequate hash length was used. The AND/OR-\acrshort{lsh} approach was also compared to an \acrshort{hnsw} implementation and was shown to produce better results in terms of infection recall. As AND/OR-\acrshort{lsh} exhibited higher infection recall values, it can be argued that the objective to prevent false negatives was achieved, as discussed in Mustafa's work \cite{Mus1}.  However, since \acrshort{hnsw} was searching for k nearest neighbors per sequence, it is rather comparable to the breadth search method of \acrshort{ccs}, which resulted in worse infection recalls than depth search. Therefore, an \acrshort{hnsw} implementation that is more appropriate to identify infection chains could be feasible.

In summary, it can be concluded that the infection chains within the aggregates were well preserved using the approaches presented in this work. This was particularly evident in the high infection recalls exhibited and the low errors of more efficiently calculated genetic distance matrices. The matrices were underestimated, particularly for short distances, which indicates that infectious distances were accurately represented. This contributes to preserving the interpretability for outbreak analysis through the representation of infection chains.

\subsection{Preservation of Outbreak Contexts}
The detected communities of the original GENTRAIN \acrshortpl{mst} showed a strong relationship with the lineage association of the sequences. The sampling dates were only represented in the node clusters of nrw\_2022. For this aggregate, the development of the clades and the order of the sampling months could be traced by following the edges between node clusters. Sequences that were collected the first formed the beginning, and the last sequences collected formed the end of this cluster chain. Clade 22D was the only exception to this pattern. It emerged at the end of the observation period but was still linked to earlier collected sequences. These findings were not observed for aggregates of shorter seasonal periods (due\_202203), which appears logical, as outbreak dynamics are more confined to specific geographic areas and genomes are more similar due to fewer opportunities for mutation. Although cities were less represented by node clusters, the samples associated with Cologne formed several separate clusters for nrw\_2022. Therefore, the observed \acrshortpl{mst} represented geographic and genomic contexts, while \acrshortpl{mst} that comprise longer seasonal periods also adequately represented the seasonal context. These observations suggest that the grouping of sequences within the resulting \acrshortpl{mst} is not arbitrary and is strongly related to seasonal and geographic attributes. It can be concluded that Louvain partitions adequately represent outbreak-related contexts within the \acrshortpl{mst}. This also highlights the significance of the community ARI metric, as it compares the Louvain partitions of two different \acrshort{mst} (see Figure \ref{fig:community_ari_impact} in Appendix \ref{app:supplementary_figures}). The community \acrshort{ari} appears to be a very strict assessment that can indicate preservation of interpretability for outbreak analysis. However, low scores do not definitively rule out such preservation.

The community \acrshort{ari} scores for the modified algorithm indicated a relatively modest preservation of the \acrshort{mst} community structure, which was an unexpected finding. This showed how sensitive this metric is when exact genetic distances are not used. The community \acrshort{ari} for \acrshort{ccs} clearly suggested that the preservation of the community structure mainly benefits from finding the lowest genetic distances (depth search) rather than considering a broad representation of sequences (breadth search). This was already observed when assessing the preservation of infection chains, which underlines the relationship between these objectives. However, since \acrshortpl{mst} minimize edge weight, this finding was not unexpected. When evaluating the preservation of the \acrshort{mst} structure using the community \acrshort{ari} for different aggregates, the scores improved as the seasonal period and the geographic area expanded. One reason for this phenomenon is that aggregates with longer seasonal periods and wider geographic areas tend to exhibit a greater deviation of the genetic distance. This is the result of greater sequence availability and, consequently, a smaller portion of sequences being obtained when obtaining equally sized samples of differently sized aggregates. The lower infection rate also supported this assumption. It is evident that a greater spread of genetic distances is advantageous in distinguishing relevant candidates. This finding is good news for realistic outbreak scenarios, as more complex seasonal and geographic contexts also have fewer sequences to consider. 

The sample size did not show a significant impact on the community \acrshort{ari}. However, asymptomatic scores for the community \acrshort{ari} were detected for the aggregate due\_202203, which had a sequence count of 2,500. Although the results for sample sizes of 1,250 and 5,000 aligned with the observed impact of seasonal period and geographic area, this aggregate showed far better community \acrshort{ari} scores when considering 2,500 sequences. Not only did this aggregate outperform sequences from the same seasonal period in \acrshort{nrw}, but it also outperformed the aggregate comprising the same geographic area with a longer seasonal period of one year. As the aggregate for nrw\_2022 did not show such a significant difference for variant sample sizes, it could be that the sample size is more significant to preserve the \acrshort{mst} structure when the aggregates show a lower genetic distance deviation. However, since the community \acrshort{ari} scores for due\_202203 varied with different sample sizes but did not correlate with them, another possible explanation for the observed phenomenon is that aggregates exhibiting smaller distance deviations are more sensitive to minor changes in the genetic distance matrices during \acrshort{mst} generation. This may not be directly related to the size of the sample, but rather to the random selection of highly similar sequences that resulted from downsampling.

The \acrshort{acs} method showed a comparable impact of different seasonal and geographic spans. Community \acrshort{ari} scores were higher when sequences of an entire year were considered compared to a month. Compared to \acrshort{hnsw}, AND/OR-\acrshort{lsh} exhibited higher community \acrshort{ari} scores for numbers of \acrshort{lsh} iterations that produced calculation rates of 0.08 or higher for the aggregate nrw\_2022. Regarding nrw\_202203 this phenomenon was observed for even lower calculation rates of 0.04 and above. In contrast, \acrshort{hnsw} yielded better results for lower calculation rates. Since \acrshort{hnsw} identifies candidates in a k nearest neighbor manner, a broad representation of sequences may be beneficial for very low calculation rates.

The mean edge weight indicated to what extent the edge weights differed compared to reference \acrshortpl{mst}. Regarding the mean edge weights produced by the modified algorithm, these were generally lower than the mean edge weights of the original \acrshortpl{mst}. This was not surprising, as an underestimation of the original algorithm was already confirmed. The difference compared to the original \acrshortpl{mst} increased with the mean edge weight exhibited, as well as with the seasonal and geographic span. For \acrshort{ccs} and \acrshort{acs} very low differences were observed in the mean edge weight compared to the modified algorithm. This showed that the \acrshortpl{mst} corresponding to the modified algorithm were adequately represented in terms of their edge weights. Most of the mean edge weights exhibited were lower than those obtained from the modified algorithm, suggesting an underestimation of the edge weights.

The lineage purity metric allowed the assessment of \acrshort{mst} structures in relation to the representation of the mutation dynamics. In general, all the approaches performed achieved very high lineage purity scores. Interestingly, generating \acrshortpl{mst} on the basis of the modified algorithm yielded slightly worse lineage purity scores than \acrshort{ccs} and \acrshort{acs}. However, the modified algorithm still showed very pure communities in terms of lineage, comparable to those of the original \acrshortpl{mst}. This emphasizes the applicability of the mutation encoding in terms of its representative value with respect to mutation dynamics. The finding also allows the conclusion that \acrshort{ccs} and \acrshort{acs} are appropriate methods to preserve the interpretability of \acrshortpl{mst} regarding the lineage associations through node clusters.

A visual analysis of the sequence distribution for \acrshortpl{mst} resulting from the modified algorithm showed that the clusters of nodes were still clearly related to lineages and sampling dates. In addition, several node clusters of sequences originating from Cologne were identified for the \acrshortpl{mst}, which is another characteristic adapted from the original \acrshort{mst}. However, it was evident that the original algorithm was superior in terms of the construction of the cluster chain for longer seasonal periods. When using the modified algorithm, the placement of the clusters associated with clades 22B and 22E was disordered. The same was observed for the sampling dates, as some of the latest sequences collected were placed in the middle of the cluster chain. This alignment can be explained by the close relationship between clades and sampling dates, since clades evolve over time.  
Similar findings were found for a sample size of 10,000. However, these findings were more pronounced, as a central node cluster of clade 21L was observed connecting several clusters of clades 22B and 22E. This emphasizes the relatedness of sequences from these clades, as the algorithm had difficulty preserving a clear distinction between them. 
Although the seasonal context was preserved within the separate clusters of nodes, the clusters containing the latest sequences collected were placed at separate positions within the cluster chain.

Since the introduced mutation encoding is the informative basis for the \acrshort{ccs} and \acrshort{acs}, it is no surprise that these approaches yielded comparable results. \acrshort{ccs} generated \acrshortpl{mst} that adequately represent lineage association through node clusters. As depth search does not focus on calculating genetic distances for all sequences considered, several nodes within the resulting \acrshortpl{mst}
remained unconnected to the primary subgraph. The number of unconnected nodes depended on the calculation rate, as higher rates led to denser genetic distance matrices. However, this must not be a disadvantage, as the only unconnected component with a large number of sequences was the clade 21K. This clade was already identified as distinct from the others, so this was not actually an information loss. One could argue that separating this clade is even beneficial because it emphasizes its distinctiveness. The distribution of sampling dates is closely related to the representation of clades. Therefore, it is not surprising that several node clusters containing sequences collected late in the observation period were also misplaced within the node cluster chain. Once again, several node clusters consisting primarily of sequences from Cologne were identified, demonstrating the representation of the geographic context. Similar observations were made when using \acrshort{acs}, although the phenomenons appeared to be more pronounced. Once again, the node clusters adequately represented lineages, sampling dates, and collection cities, although they did not completely preserve the sequential order of the clusters. The \acrshort{mst} also contained a central cluster connecting multiple clusters of different clades. As observed for the corresponding $T$\textsubscript{mst}, the seasonal order of sampling extraction is not adequately represented. As seen for the other approaches, the clades 21K and 21L exhibited the most robust results in terms of the placement within the cluster chain.

The approaches proposed in this work provided accurate representations of genetic, seasonal, and geographic relationships based on the resulting clusters of nodes. Less consistent results were obtained in preserving the sequential relationship between different clusters. Since the group of nodes associated with clade 21K showed consistent placement and separation from the other sequences for all the approaches carried out, one might argue that these sequences are more distinct from sequences from other clades. Therefore, minor changes in genetic distance can lead to less significant changes in the \acrshort{mst} topology. In contrast, other clades, and particularly clades 22B and 22E, might be more similar in terms of the mutations contained. The fact that the original GENTRAIN algorithm was able to distinguish based on these minor changes emphasizes its value for outbreak analysis. When the introduced approaches were implemented, it was not expected that not assessing the proper symbols and the underestimation of distances resulting from indels would produce such significant differences regarding the sequential chaining of clusters. However, since large node clusters were connected by very low distances, it is reasonable to assume that their sequential arrangement is not very robust. Nevertheless, given the significant runtime improvements achieved, this may be an acceptable compromise, since the outbreak contexts in the resulting \acrshort{mst} are still clearly distinct from each other. Therefore, the interpretability for outbreak analysis was well preserved, particularly regarding the representation of the outbreak contexts within separate node clusters.

\subsection{Applicability and Limitations}
This work addressed the research question by providing adequate solutions concerning various dimensional scenarios in terms of the number of sequences under observation. 
When working with sequences around 1,000 in number, it is questionable whether the runtime savings from a selective genetic distance calculation are worth the loss of accuracy. Although datasets comprising around 5,000 sequences and less are yet manageable using the \acrshort{ccs}, a larger number of sequences suggests utilizing \acrshort{acs}. The concrete implementation of \acrshort{acs} that yields the best results remains to be identified, although initial suggestions were made in the context of this work. The approaches considered may be further extended by the concepts included in Grabowski and Kowalski's research, which also addressed the selective calculation of Hamming distances using various methods \cite{Gra1}. Furthermore, the applicability of \acrshort{hnsw} regarding visualizations to support outbreak analysis can be assessed more thoroughly. Although this work focused on Mustafa's work, which deals with \acrshort{lsh} to minimize false negatives, \acrshort{hnsw} implementations like GSEARCH demonstrate great potential, as shown by Zhao et al. \cite{Zha1}.

The applied methods focused on the SARS-CoV-2 virus due to its extensive sequence availability. \acrshortpl{snv} and deletions were identified as the main drivers of the SARS-CoV-2 mutation dynamics. Considering insertions when encoding mutation data improved transferability to other viruses, as they may exhibit different characteristics in their mutation dynamics. Analyzing mutation information with Nextclade only requires a reference genome for specific viruses, which should be feasible for common pathogens. However, further investigation is necessary to determine the applicability of the presented results to other viruses. For example, the behavior of viral mutations may affect the requirements for the mutation encoding structure. It is also questionable whether other viruses provide sufficient sequence data availability for a comparable investigation. In addition to focusing on the SARS-CoV-2 virus, this work only examined the GENTRAIN algorithm. Although the goal was to maintain transferability to other implementations, those still need to be evaluated separately. Algorithms dealing with aligned sequences should produce comparable results. However, this work did not address comparing unaligned sequences.

A major challenge of this work was to identify data aggregates that could adequately represent various plausible outbreak scenarios while maintaining a reasonable scope. Since evaluating a single data aggregate was elaborate and time consuming, only some of the possible result sets were included. Consequently, the presented results do not encompass all possibilities in sequence selection. However, the distinction of aggregates based on seasonal and geographic aspects aimed to mitigate this incompleteness in terms of unconsidered outbreak scenarios. Furthermore, the quantitative evaluation of this work was based on a modified algorithm that resulted in poorer preservation of the sequential cluster chains. This was done to minimize the effort required for the evaluation against a complete distance matrix. Conclusions could still be drawn regarding the original algorithm since the modified algorithm was initially compared to the GENTRAIN algorithm, and $T$\textsubscript{gen} was considered when visually analyzing the resulting \acrshortpl{mst}. However, a study with a longer timeframe could provide a more thorough quantitative evaluation against the original algorithm.

In real-world scenarios, the metrics used in this work may differ in significance. For example, when analyzing the spread of disease in an urban scenario with short distances and high infection rates expected, the focus would be on preserving infection chains. This was primarily assessed using infection recall and error metrics. The community \acrshort{ari} may be less informative in such scenarios because the community structures of \acrshort{mst} are more sensible for high infection rates than for lower rates. In contrast, the community \acrshort{ari} may be more significant when evaluating the spread of viruses across multiple federal states or countries. Furthermore, a strict evaluation of \acrshort{mst} community arrangements may be beneficial for retrospective observations, as these often cover longer seasonal periods and geographic areas.

This work did not extensively evaluate the preservation of the fine-grained outbreak dynamics within the identified Louvain communities. Although these were considered when examining correlations, errors, mean edge weights, and infection recall scores for genetic distance matrices, a thorough visual analysis could offer additional confirmation that these nuances were preserved.
Furthermore, the Louvain algorithm utilizes modularity to find the best partitions of node communities without considering actual edge weights. This can result in outlier nodes being assigned to communities, even when the edge weight exceeds expectations for community assignment. As this work focused on very large datasets, the risk of outliers was accepted as they were very rare.

The research question was motivated by the optimistic expectation that sequence genomics will be further established in public health systems. This expectation is also supported by the potential attributed to \acrshort{igs} in existing research \cite{Blu1, Han1}. Without this progression, the availability of sequences might never reach a stage at which real-time observations of large-scale infection chain dynamics, as discussed in this work, becomes relevant. However, as history has shown, catastrophic scenarios, such as pandemics, can suddenly increase the need for such visualizations and inevitably increase sequence availability. Furthermore, analyzing the dynamics of large-scale infection chain dynamics can play an important role in retrospective analysis of viral spread.

Since this work only addressed the general possibility of generating outbreak visualizations in a decreased amount of time, subsequent research should focus on assessing realistic scenarios and runtime acceptance. As GENTRAIN represents a pioneer in the combination of genomic science and user-oriented applications, there is also a lack of scientific research on benchmarking acceptable runtime for bioinformatic processes. In addition, it is questionable which sizes of sequence datasets are practicable for the visualization of outbreak scenarios and which exceed the limits of productive processability. To ensure interpretability in very large-scale scenarios, one option may be to visually group node clusters. This approach was proposed by Argimón et al. to improve Microreact's ability to visualize large-scale graphs \cite{Mic1}. Comparable applications, such as Nextstrain and Microreact, do not currently address computational challenges for large-scale datasets \cite{Nex9, Mic1}. As demonstrated in \ref{cha:related_work}, Nextstrain could not process a large number of sequences simultaneously in the web browser. This is a challenge that GENTRAIN must also overcome.

Finally, this work was carried out within a media informatics department. Although care was taken to explain the necessary genomic basics for understanding and elaboration, no claim of completeness is made regarding the principles presented. Therefore, it would be beneficial to have scientific contributors with deeper genomics expertise further elaborate on the results. In addition, the findings could be substantiated by using a more appropriate technical environment, since the processes were executed on a commercially available MacBook Air. Although an effort was made to create similar execution conditions, the resulting runtimes may have been influenced by other processes running in parallel. Therefore, this evaluation may be distorted, while still being suitable for a general comparison of the approaches, as it continues to demonstrate the relative differences in runtime between the implemented approaches.
